"""
Step 7: æ–°å‹•ç”»ã®PDCAè©•ä¾¡ â†’ ãƒ¢ãƒ‡ãƒ«æ›´æ–°

å®Ÿè¡Œæ–¹æ³•:
  python scripts/step7_pdca.py VIDEO_ID
  python scripts/step7_pdca.py VIDEO_ID --skip-fetch
  python scripts/step7_pdca.py VIDEO_ID --skip-fetch --update-model

å‹•ä½œ:
  1. æ–°å‹•ç”»ã®ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆ--skip-fetch ã§çœç•¥å¯ï¼‰
  2. ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒ â†’ äºˆæ¸¬ vs å®Ÿç¸¾ã‚’è©•ä¾¡
  3. PDCAãƒ¬ãƒãƒ¼ãƒˆã‚’ data/output/ ã«å‡ºåŠ›
  4. --update-model ã‚’ä»˜ã‘ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰ï¼ˆstep2_build_modelçµŒç”±ï¼‰

é‹ç”¨ã‚µã‚¤ã‚¯ãƒ«:
  æ–°å‹•ç”»å…¬é–‹ â†’ Day7ã§å®Ÿè¡Œ â†’ ãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
  â†’ æ‰‹å‹•CSVæ›´æ–° + å°æœ¬åˆ†æž â†’ --update-model ã§ãƒ¢ãƒ‡ãƒ«æ›´æ–°
"""

import argparse
import json
import os
import sys
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import VIDEOS_DIR, DATA_DIR, MODEL_FILE, HIT_THRESHOLD, OUTPUT_DIR, PREDICTIONS_FILE
from common.data_loader import validate_fundamentals
from step1_fetch import fetch_single_video
from step2_build_model import build_and_save


def load_model():
    if not os.path.exists(MODEL_FILE):
        print("âŒ model.json ãŒã‚ã‚Šã¾ã›ã‚“ã€‚step2_build_model.py ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None
    with open(MODEL_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def evaluate(video_data, model):
    """äºˆæ¸¬ vs å®Ÿç¸¾ã‚’è©•ä¾¡"""
    views = video_data["metadata"]["current_stats"]["view_count"]
    title = video_data["metadata"]["title"]
    artist = (video_data.get("manual_data") or {}).get("artist_name", title[:20])

    # ãƒ†ã‚£ã‚¢åˆ¤å®š
    if views >= 500000:
        tier = "S_500k+"
    elif views >= 200000:
        tier = "A_200k-500k"
    elif views >= 100000:
        tier = "B_100k-200k"
    else:
        tier = "C_under_100k"

    # ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ†æž
    traffic = video_data.get("traffic_sources", {})
    browse_pct = traffic.get("BROWSE", {}).get("percentage", 0)
    related_pct = traffic.get("RELATED_VIDEO", {}).get("percentage", 0)

    # Dayå¤‰åŒ–
    daily = video_data.get("daily_data", {})
    day_change = daily.get("day1_to_day2_change_percent")

    return {
        "video_id": video_data["metadata"]["video_id"],
        "artist_name": artist,
        "title": title,
        "actual_views": views,
        "actual_tier": tier,
        "is_hit": views >= HIT_THRESHOLD,
        "browsing_percent": browse_pct,
        "related_percent": related_pct,
        "day2_change": day_change,
        "hook_fraud_detected": day_change is not None and day_change <= -50,
        "evaluation_date": datetime.now().isoformat(),
    }


def generate_pdca_report(ev, video_data, model):
    """PDCAãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    o = video_data.get("analytics_overview", {})
    corrs = model.get("correlations", {})

    lines = [
        f"# PDCAè©•ä¾¡: {ev['artist_name']}",
        f"\nè©•ä¾¡æ—¥: {ev['evaluation_date'][:10]}",
        f"\n## å®Ÿç¸¾",
        f"\n| é …ç›® | å€¤ |", "|------|-----|",
        f"| å†ç”Ÿæ•° | {ev['actual_views']:,} |",
        f"| ãƒ†ã‚£ã‚¢ | {ev['actual_tier']} |",
        f"| åˆ¤å®š | {'ðŸ”¥ ãƒ’ãƒƒãƒˆ' if ev['is_hit'] else 'ðŸ“‰ ä¸æŒ¯'} |",
        f"| ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚° | {ev['browsing_percent']}% |",
        f"| é–¢é€£å‹•ç”» | {ev['related_percent']}% |",
    ]

    if ev.get("day2_change") is not None:
        flag = " âš ï¸ãƒ•ãƒƒã‚¯è©æ¬ºç–‘ã„" if ev["hook_fraud_detected"] else ""
        lines.append(f"| Day1â†’Day2 | {ev['day2_change']:+.1f}%{flag} |")

    # ãƒ¢ãƒ‡ãƒ«æŒ‡æ¨™ã¨ã®æ¯”è¼ƒ
    if o:
        lines.extend([
            f"\n## ãƒ¢ãƒ‡ãƒ«æŒ‡æ¨™ã¨ã®æ¯”è¼ƒ",
            f"\n| æŒ‡æ¨™ | ã“ã®å‹•ç”» | ãƒ¢ãƒ‡ãƒ«ç›¸é–¢ |", "|------|---------|----------|",
        ])
        checks = [
            ("å…¨ä½“CTR", f"{o.get('impression_ctr', 0):.2f}%"),
            ("å¹³å‡è¦–è´æ™‚é–“(ç§’)", f"{o.get('average_view_duration_seconds', 0):.0f}"),
            ("ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°", f"{o.get('impressions', 0):,}"),
        ]
        for name, display in checks:
            r = corrs.get(name, "N/A")
            lines.append(f"| {name} | {display} | r={r} |")

    # ã‚°ãƒ«ãƒ¼ãƒ—æ¯”è¼ƒ
    comp = model.get("group_comparisons", {})
    if ev["is_hit"] and "ä¼¸ã³ãŸå‹•ç”»" in comp:
        avg = comp["ä¼¸ã³ãŸå‹•ç”»"].get("å¹³å‡å†ç”Ÿæ•°", 0)
        lines.append(f"\nä¼¸ã³ãŸå‹•ç”»ã®å¹³å‡({avg:,})ã«å¯¾ã—ã¦ {ev['actual_views']/avg*100:.0f}%" if avg else "")
    elif not ev["is_hit"] and "ä¼¸ã³ã¦ãªã„å‹•ç”»" in comp:
        avg = comp["ä¼¸ã³ã¦ãªã„å‹•ç”»"].get("å¹³å‡å†ç”Ÿæ•°", 0)
        lines.append(f"\nä¼¸ã³ã¦ãªã„å‹•ç”»ã®å¹³å‡({avg:,})ã«å¯¾ã—ã¦ {ev['actual_views']/avg*100:.0f}%" if avg else "")

    lines.extend([
        f"\n## å­¦ã³ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
        f"\nä»¥ä¸‹ã‚’Claude Codeã§åˆ†æžã—ã¦ãã ã•ã„:",
        f"- ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã¯æ­£ã—ã‹ã£ãŸã‹ï¼Ÿ",
        f"- äºˆæ¸¬ã¨ä¹–é›¢ã—ãŸåŽŸå› ã¯ä½•ã‹ï¼Ÿ",
        f"- ãƒ¢ãƒ‡ãƒ«ã«è¿½åŠ ã™ã¹ãæ–°ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã‚ã‚‹ã‹ï¼Ÿ",
        f"- é–¾å€¤ã‚„ä¿‚æ•°ã‚’ä¿®æ­£ã™ã¹ãã‹ï¼Ÿ",
        f"\n### æ›´æ–°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ",
        f"- [ ] model.json ã®æ›´æ–°ãŒå¿…è¦",
        f"- [ ] selection.md ã®åŸºæº–å€¤ã‚’ä¿®æ­£",
        f"- [ ] ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ä¿®æ­£",
    ])

    return "\n".join(lines)


def find_prediction(artist_name):
    """predictions.jsonl ã‹ã‚‰è©²å½“ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æœ€æ–°pendingäºˆæ¸¬ã‚’æ¤œç´¢ã€‚

    å®Œå…¨ä¸€è‡´ â†’ éƒ¨åˆ†ä¸€è‡´ï¼ˆäºˆæ¸¬åãŒartist_nameã«å«ã¾ã‚Œã‚‹ï¼‰ã®é †ã§ç…§åˆã€‚
    """
    if not os.path.exists(PREDICTIONS_FILE):
        return None
    normalize = lambda s: s.lower().replace(" ", "").replace("ã€€", "")
    target = normalize(artist_name)
    exact = None
    partial = None
    with open(PREDICTIONS_FILE, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            rec = json.loads(line)
            if rec.get("type") == "verification":
                continue
            if rec.get("status") != "pending":
                continue
            pred_name = normalize(rec.get("artist_name", ""))
            if pred_name == target:
                exact = rec
            elif pred_name and pred_name in target:
                partial = rec
    return exact or partial


def append_verification(prediction, ev):
    """æ¤œè¨¼ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’predictions.jsonl ã«è¿½è¨˜ï¼ˆå…ƒã®äºˆæ¸¬è¡Œã¯ä¸å¤‰ï¼‰ã€‚"""
    verification = {
        "type": "verification",
        "prediction_id": prediction["prediction_id"],
        "verification_date": datetime.now().isoformat(),
        "video_id": ev["video_id"],
        "actual": {
            "views": ev["actual_views"],
            "tier": ev["actual_tier"],
            "is_hit": ev["is_hit"],
        },
        "comparison": {
            "prediction_correct": prediction["prediction"]["hit_or_miss"] == ("HIT" if ev["is_hit"] else "MISS"),
            "predicted_hit": prediction["prediction"]["hit_or_miss"] == "HIT",
            "actual_hit": ev["is_hit"],
        },
    }
    with open(PREDICTIONS_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(verification, ensure_ascii=False) + "\n")


def generate_prediction_comparison(prediction, ev):
    """äºˆæ¸¬ç…§åˆã‚»ã‚¯ã‚·ãƒ§ãƒ³(Markdownæ–‡å­—åˆ—)ã‚’ç”Ÿæˆã€‚"""
    p = prediction["prediction"]
    correct = p["hit_or_miss"] == ("HIT" if ev["is_hit"] else "MISS")
    actual_hm = "HIT" if ev["is_hit"] else "MISS"
    match_str = lambda a, b: "OK" if a == b else "NG"
    conf_label = {"high": "é«˜", "medium": "ä¸­", "low": "ä½Ž"}.get(p["confidence"], p["confidence"])

    lines = [
        "## äºˆæ¸¬ç…§åˆ",
        f"\n| é …ç›® | äºˆæ¸¬ | å®Ÿç¸¾ | ä¸€è‡´ |",
        "|------|------|------|------|",
        f"| HIT/MISS | {p['hit_or_miss']} | {actual_hm} | {match_str(p['hit_or_miss'], actual_hm)} |",
        f"| ãƒ©ãƒ³ã‚¯ | {p['rank']} | {ev['actual_tier']} | - |",
        f"| ä¿¡é ¼åº¦ | {conf_label} | - | - |",
        f"\näºˆæ¸¬æ—¥: {prediction['prediction_date'][:10]}",
        f"æ ¹æ‹ : {p['reasoning']}",
        f"çµæžœ: {'äºˆæ¸¬çš„ä¸­' if correct else 'äºˆæ¸¬å¤–ã‚Œ'}",
    ]
    return "\n".join(lines)


def update_model():
    """æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰ï¼ˆstep2_build_modelçµŒç”±ï¼‰"""
    print("\nãƒ¢ãƒ‡ãƒ«å†æ§‹ç¯‰ä¸­...")
    model, _ = build_and_save()
    return model


def main():
    parser = argparse.ArgumentParser(description="Step 4: PDCAè©•ä¾¡ãƒ»ãƒ¢ãƒ‡ãƒ«æ›´æ–°")
    parser.add_argument("video_id", help="è©•ä¾¡ã™ã‚‹å‹•ç”»ID")
    parser.add_argument("--skip-fetch", action="store_true", help="ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    parser.add_argument("--update-model", action="store_true", help="ãƒ¢ãƒ‡ãƒ«ã‚‚å†æ§‹ç¯‰")
    args = parser.parse_args()

    print("=" * 50)
    print(f"Step 4: PDCAè©•ä¾¡ - {args.video_id}")
    print("=" * 50)

    # ä¸å¤‰åŸºç›¤ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ (W-23)
    validate_fundamentals()

    model = load_model()
    if not model:
        return

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    if not args.skip_fetch:
        print("\n[1/3] ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        fetch_single_video(args.video_id)
    else:
        print("\n[1/3] ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚­ãƒƒãƒ—")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    json_path = os.path.join(VIDEOS_DIR, f"{args.video_id}.json")
    if not os.path.exists(json_path):
        print(f"âŒ {json_path} ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    with open(json_path, "r", encoding="utf-8") as f:
        video_data = json.load(f)

    # è©•ä¾¡
    print("[2/3] PDCAè©•ä¾¡ä¸­...")
    ev = evaluate(video_data, model)

    # ãƒ¬ãƒãƒ¼ãƒˆ
    report = generate_pdca_report(ev, video_data, model)

    # äºˆæ¸¬ç…§åˆ
    prediction = find_prediction(ev["artist_name"])
    if prediction:
        report += "\n\n" + generate_prediction_comparison(prediction, ev)
        append_verification(prediction, ev)
        print(f"  äºˆæ¸¬ç…§åˆå®Œäº†: {prediction['prediction_id']}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    rpath = os.path.join(OUTPUT_DIR, f"pdca_{args.video_id}_{datetime.now().strftime('%Y%m%d')}.md")
    with open(rpath, "w", encoding="utf-8") as f:
        f.write(report)
    print(f"  âœ… PDCAãƒ¬ãƒãƒ¼ãƒˆ: {rpath}")

    # ãƒ­ã‚°
    log_path = os.path.join(DATA_DIR, "pdca_log.jsonl")
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(ev, ensure_ascii=False) + "\n")

    # ãƒ¢ãƒ‡ãƒ«æ›´æ–°
    if args.update_model:
        print("\n[3/3] ãƒ¢ãƒ‡ãƒ«æ›´æ–°ä¸­...")
        update_model()
    else:
        print(f"\n[3/3] ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚¹ã‚­ãƒƒãƒ—")
        print(f"  â†’ æ›´æ–°ã™ã‚‹å ´åˆ: python scripts/step7_pdca.py {args.video_id} --skip-fetch --update-model")

    # ã‚µãƒžãƒªãƒ¼
    print(f"\n{'='*50}")
    print(f"å®Œäº†: {ev['artist_name']}")
    print(f"  {ev['actual_views']:,}å›ž â†’ {ev['actual_tier']} {'ðŸ”¥' if ev['is_hit'] else 'ðŸ“‰'}")
    if ev.get("hook_fraud_detected"):
        print(f"  âš ï¸ ãƒ•ãƒƒã‚¯è©æ¬ºç–‘ã„ï¼ˆDay2: {ev['day2_change']:+.1f}%ï¼‰")
    print("=" * 50)


if __name__ == "__main__":
    main()
